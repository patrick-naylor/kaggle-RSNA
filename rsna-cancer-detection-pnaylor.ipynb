{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install python-gdcm pylibjpeg --no-index --find-links \"../input/rsna-wheels/\"","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:03:34.942513Z","iopub.execute_input":"2022-12-28T22:03:34.942975Z","iopub.status.idle":"2022-12-28T22:03:47.493869Z","shell.execute_reply.started":"2022-12-28T22:03:34.942868Z","shell.execute_reply":"2022-12-28T22:03:47.492706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone\n%cd yolov5\n%pip install -qr requirements.txt  # install\n\nimport torch\n\ndevice = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:03:47.496197Z","iopub.execute_input":"2022-12-28T22:03:47.496846Z","iopub.status.idle":"2022-12-28T22:04:32.116710Z","shell.execute_reply.started":"2022-12-28T22:03:47.496801Z","shell.execute_reply":"2022-12-28T22:04:32.115687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import f1_score\nimport torch.nn as nn\nfrom torchvision import transforms\nimport torch.optim as optim\nimport numpy as np\nimport os\nimport pydicom\nfrom pydicom.pixel_data_handlers import apply_windowing\nimport torch.nn.functional as F\nfrom torchmetrics.classification import BinaryF1Score","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:04:32.118298Z","iopub.execute_input":"2022-12-28T22:04:32.118924Z","iopub.status.idle":"2022-12-28T22:04:34.491771Z","shell.execute_reply.started":"2022-12-28T22:04:32.118883Z","shell.execute_reply":"2022-12-28T22:04:34.490582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roi_extractor_model = torch.hub.load('/kaggle/input/yolov5-repo', 'custom', path='/kaggle/input/rsna-breast-cancer-detection-roi-model/rsna-roi-003.pt', source='local')","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:04:34.495018Z","iopub.execute_input":"2022-12-28T22:04:34.495398Z","iopub.status.idle":"2022-12-28T22:04:40.009347Z","shell.execute_reply.started":"2022-12-28T22:04:34.495358Z","shell.execute_reply":"2022-12-28T22:04:40.008450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"code","source":"# helper functions\ndef read_dicom_with_windowing(dcm_file):\n    # from: https://www.kaggle.com/code/davidbroberts/mammography-apply-windowing/\n    im = pydicom.dcmread(dcm_file)\n    data = im.pixel_array\n    \n    # This line is the only difference in the two functions\n    data = apply_windowing(data, im)\n    \n    if im.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    else:\n        data = data - np.min(data)\n        \n    if np.max(data) != 0:\n        data = data / np.max(data)\n    data=(data * 255).astype(np.uint8)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:04:40.010934Z","iopub.execute_input":"2022-12-28T22:04:40.011322Z","iopub.status.idle":"2022-12-28T22:04:40.018510Z","shell.execute_reply.started":"2022-12-28T22:04:40.011281Z","shell.execute_reply":"2022-12-28T22:04:40.017091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_yolo_ROI(image):\n    # https://www.kaggle.com/code/remekkinas/breast-cancer-roi-brest-extractor/notebook\n    detections = roi_extractor_model(image)\n    \n    bbox_df = detections.pandas().xyxy[0]\n    bbox_df.drop([\"name\"], axis=1, inplace=True)\n    bboxes = bbox_df.astype(int).to_dict(orient=\"records\")\n    \n    if len(bboxes) == 0:\n        return image\n    \n    if len(bboxes) != 1:\n        print(bboxes)\n        print(\"More than one ROI detected\")\n\n    bbox = bboxes[0]\n    \n    image = image[bbox[\"ymin\"]:bbox[\"ymax\"], bbox[\"xmin\"]:bbox[\"xmax\"]]\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:04:40.020306Z","iopub.execute_input":"2022-12-28T22:04:40.021152Z","iopub.status.idle":"2022-12-28T22:04:40.037301Z","shell.execute_reply.started":"2022-12-28T22:04:40.021116Z","shell.execute_reply":"2022-12-28T22:04:40.036222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BreastCancerDataset(torch.utils.data.Dataset):\n    # image to cancer\n    def __init__(self, df, dataset_folder, transform=None):\n        self.dataset_folder = dataset_folder\n        self.transform = transform\n        \n        if \"breast_id\" not in df.columns:\n            df[\"breast_id\"] = df[\"patient_id\"].astype(str) + \"_\" + df[\"laterality\"]\n\n        if \"image_path\" not in df.columns:\n            df[\"image_path\"] = df[\"patient_id\"].astype(str) + \"/\" + df[\"image_id\"].astype(str) + \".dcm\"\n\n        self.df = df\n        if 'cancer' in self.df.columns:\n            self.subset = 'train'\n        else:\n            self.subset = 'test'\n\n    def __len__(self):\n        return len(self.df.groupby(\"breast_id\"))\n\n    def __getitem__(self, idx):\n        # return MLO and CC images from given breast\n        breast_id = self.df[\"breast_id\"].unique()[idx]\n        breast_df = self.df[self.df[\"breast_id\"] == breast_id]\n        \n        MLO = breast_df[breast_df[\"view\"] == \"MLO\"]\n        CC = breast_df[breast_df[\"view\"] == \"CC\"]\n\n        MLO_image_path = os.path.join(self.dataset_folder, self.subset+ \"_images\", MLO[\"image_path\"].values[0])\n        CC_image_path = os.path.join(self.dataset_folder, self.subset+ \"_images\", CC[\"image_path\"].values[0])\n\n        MLO_image = read_dicom_with_windowing(MLO_image_path)\n        CC_image = read_dicom_with_windowing(CC_image_path)\n        \n        MLO_image = crop_yolo_ROI(MLO_image)\n        CC_image = crop_yolo_ROI(CC_image)\n\n        MLO_image = torch.from_numpy(MLO_image)\n        CC_image = torch.from_numpy(CC_image)\n        \n        if self.transform:  # normalization and augmentation are in here\n            MLO_image = self.transform(MLO_image)\n            CC_image = self.transform(CC_image)\n        \n        # add these images into a 2 channel image\n        image = torch.cat([MLO_image, CC_image], dim=0)\n\n        if self.subset == 'train':\n            label = breast_df['cancer'].values[0]\n            return image, label\n        \n        \n        return image","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:04:40.038851Z","iopub.execute_input":"2022-12-28T22:04:40.039633Z","iopub.status.idle":"2022-12-28T22:04:40.054596Z","shell.execute_reply.started":"2022-12-28T22:04:40.039593Z","shell.execute_reply":"2022-12-28T22:04:40.053472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ntest_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n\ndataset_folder = '/kaggle/input/rsna-breast-cancer-detection'\n\ntransform = transforms.Compose([ # also add augmentation\n    transforms.ToPILImage(),\n    transforms.Resize((100, 100)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = BreastCancerDataset(train_df, dataset_folder, transform=transform)\ntest_dataset = BreastCancerDataset(test_df, dataset_folder, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T00:40:14.312125Z","iopub.execute_input":"2022-12-29T00:40:14.312820Z","iopub.status.idle":"2022-12-29T00:40:14.514137Z","shell.execute_reply.started":"2022-12-29T00:40:14.312777Z","shell.execute_reply":"2022-12-29T00:40:14.513158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_df)\nprint(train_df.columns)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T00:40:53.164646Z","iopub.execute_input":"2022-12-29T00:40:53.165041Z","iopub.status.idle":"2022-12-29T00:40:53.175727Z","shell.execute_reply.started":"2022-12-29T00:40:53.165009Z","shell.execute_reply":"2022-12-29T00:40:53.174537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot first batch\nbatch_size = 32\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 4, shuffle=False)\nimages, labels = next(iter(train_loader))\n\nprint(images.shape, labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T00:47:21.252394Z","iopub.execute_input":"2022-12-29T00:47:21.252747Z","iopub.status.idle":"2022-12-29T00:48:44.956296Z","shell.execute_reply.started":"2022-12-29T00:47:21.252718Z","shell.execute_reply":"2022-12-29T00:48:44.955125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        input_size = 100*100*.25*.25*12\n        self.conv1 = nn.Conv2d(2, 6, 5, padding='same')\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 12, 5, padding='same')\n        self.fc1 = nn.Linear(int(input_size), int(input_size * .33))\n        #self.fc2 = nn.Linear(int(input_size*.33), int(input_size * .33**2))\n        self.fc3 = nn.Linear(int(input_size * .33), 1)\n        \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.sigmoid(self.fc3(x))\n        x = torch.flatten(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:06:04.240127Z","iopub.execute_input":"2022-12-28T22:06:04.240709Z","iopub.status.idle":"2022-12-28T22:06:04.251887Z","shell.execute_reply.started":"2022-12-28T22:06:04.240679Z","shell.execute_reply":"2022-12-28T22:06:04.250821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model = CNN().to(device)\ncriterion = nn.BCELoss()\noptimizer = optim.SGD(cnn_model.parameters(), lr=.001, momentum=.9)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:06:04.253569Z","iopub.execute_input":"2022-12-28T22:06:04.254637Z","iopub.status.idle":"2022-12-28T22:06:04.541323Z","shell.execute_reply.started":"2022-12-28T22:06:04.254602Z","shell.execute_reply":"2022-12-28T22:06:04.540305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 1\nn_total_steps = len(train_loader)\nfor epoch in range(num_epochs):\n    f1 = 0\n    for idx, (image, target) in enumerate(train_loader):\n        target = target.to(device)\n        image = image.to(device)\n        outputs=cnn_model(image)\n\n        loss = criterion(outputs, target.float())\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        output_binary = torch.Tensor.cpu(outputs).detach().numpy()\n        output_binary[output_binary > .5] = 1\n        output_binary[output_binary<=.5] = 0\n        f1 += f1_score(output_binary, torch.Tensor.cpu(target).numpy())\n        if idx%5 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], {idx+1}/{n_total_steps}, Loss: {loss.item():.4f}, F1: {f1/(5):.4f}')\n            f1 = 0\n        if idx > 50:\n            break","metadata":{"execution":{"iopub.status.busy":"2022-12-28T22:06:04.542780Z","iopub.execute_input":"2022-12-28T22:06:04.543139Z","iopub.status.idle":"2022-12-29T00:29:12.763069Z","shell.execute_reply.started":"2022-12-28T22:06:04.543100Z","shell.execute_reply":"2022-12-29T00:29:12.762039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for images in test_loader:\n        images = images.to(device)\n        outputs = cnn_model(images)\noutputs = torch.Tensor.cpu(outputs).numpy()\nprint(outputs)\nsubmission = {}\nsubmission['prediction_id'] = ['10008_L', '10008_R']\nsubmission['cancer'] = outputs\nsubmission_df = pd.DataFrame(submission)\nprint(submission_df)\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-29T00:52:38.817575Z","iopub.execute_input":"2022-12-29T00:52:38.818567Z","iopub.status.idle":"2022-12-29T00:52:41.423879Z","shell.execute_reply.started":"2022-12-29T00:52:38.818527Z","shell.execute_reply":"2022-12-29T00:52:41.422790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}